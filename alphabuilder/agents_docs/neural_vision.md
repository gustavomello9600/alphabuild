# ü§ñ MISS√ÉO: AGENTE 03 (NEURAL_VISION)

**Fun√ß√£o:** Arquiteto de Deep Learning (Swin-UNETR & Physics-Aware AI).
**Paradigma:** Funcional Pr√°tico (PyTorch / MONAI).
**Stack:** Python 3.10+, PyTorch, MONAI (Medical Open Network for AI), Einops.

---

## 1. CONTEXTO E OBJETIVO
Sua responsabilidade √© implementar o "C√©rebro" do **AlphaBuilder v1.1**.
Voc√™ deve abandonar a abordagem ViT pura e implementar uma arquitetura **Swin-UNETR (Swin Transformer U-Net)**.

**Por que Swin-UNETR?**
O problema de otimiza√ß√£o topol√≥gica exige duas compet√™ncias simult√¢neas:
1.  **Vis√£o Global (Encoder Swin):** Entender o fluxo de carga macrosc√≥pico (ex: "Isso √© uma viga em balan√ßo, preciso refor√ßar a base").
2.  **Precis√£o Local (Decoder U-Net):** Decidir exatamente qual voxel da borda remover para alisar a estrutura sem desconectar.

---

## 2. ESTRUTURAS DE DADOS (INTERFACE)

Defina estas estruturas utilizando `dataclasses` imut√°veis.

```python
from dataclasses import dataclass
import torch
from typing import Tuple

# Constantes do Espa√ßo Can√¥nico de Entrada
# Tensor 5D: (Batch, Channels, Depth, Height, Width)
INPUT_SHAPE = (5, 16, 64, 64) # Exemplo, ajust√°vel via config
CHANNELS = 5 

# Canal 0: Densidade (0=Ar, 1=Material)
# Canal 1: M√°scara de Suporte (1=Fixo)
# Canal 2: For√ßa X (Normalizada)
# Canal 3: For√ßa Y (Normalizada)
# Canal 4: For√ßa Z (Normalizada)

@dataclass(frozen=True)
class VolumetricInput:
    """
    Container imut√°vel para o tensor de entrada.
    Shape esperado: (Batch, 5, D, H, W)
    """
    tensor: torch.Tensor

@dataclass(frozen=True)
class ModelOutput:
    """
    Sa√≠da Dual-Head da Rede.
    """
    policy_logits: torch.Tensor  # Shape: (Batch, 2, D, H, W) -> [Add_Score, Remove_Score]
    value_pred: torch.Tensor     # Shape: (Batch, 1) -> Probabilidade de Sucesso / Compliance Estimado
```

---

## 3. TAREFAS DE IMPLEMENTA√á√ÉO

### 3.1. Arquitetura: Physics-Aware Swin-UNETR
Implemente o modelo utilizando `monai.networks.nets.SwinUNETR` como base ou implemente do zero se precisar de customiza√ß√£o fina nos embeddings de for√ßa.

*   **`build_swin_unetr(input_shape: Tuple[int, ...]) -> torch.nn.Module`**
    *   **Encoder (Swin Transformer):**
        *   Utiliza *Shifted Windows* para capturar depend√™ncias de longo alcance com complexidade linear.
        *   Extrai features em 4 escalas hier√°rquicas.
    *   **Bottleneck:**
        *   Representa√ß√£o latente compacta da f√≠sica global do problema.
    *   **Decoder (U-Net style):**
        *   Reconstr√≥i a resolu√ß√£o espacial usando Deconvolu√ß√µes (Transpose Conv).
        *   **Skip Connections:** Concatena features do Encoder para recuperar detalhes geom√©tricos perdidos.
    *   **Heads (Sa√≠das):**
        1.  **Policy Head ($1 \times 1 \times 1$ Conv):** Produz 2 canais de sa√≠da (Logits para A√ß√£o ADD e A√ß√£o REMOVE) com a mesma resolu√ß√£o espacial do input.
        2.  **Value Head (MLP no Bottleneck):** Global Average Pooling sobre o bottleneck -> MLP -> Escalar.

### 3.2. Pr√©-processamento de For√ßas
A rede deve ser invariante √† magnitude absoluta das for√ßas, mas sens√≠vel √† dire√ß√£o e propor√ß√£o.

*   **`normalize_forces(force_tensor: torch.Tensor) -> torch.Tensor`**
    *   Normaliza os canais de for√ßa (2, 3, 4) para o intervalo $[-1, 1]$ ou $[0, 1]$ baseando-se na for√ßa m√°xima presente no grid.
    *   Isso garante que uma carga de 100N e uma de 1000N gerem a "mesma" topologia relativa se o material for linear el√°stico.

### 3.3. API de Infer√™ncia
Exponha uma fun√ß√£o simples para o MCTS.

*   **`predict_action_value(model, grid_tensor: torch.Tensor) -> ModelOutput`**
    *   Recebe o grid bruto.
    *   Executa o forward pass.
    *   Aplica `softmax` na Policy Head (opcional, dependendo de como o MCTS consome).
    *   Retorna `ModelOutput`.

---

## 4. REQUISITOS T√âCNICOS

1.  **Framework:** Migra√ß√£o para **PyTorch** √© recomendada dada a disponibilidade de implementa√ß√µes Swin-UNETR robustas (MONAI). Se preferir TensorFlow, ter√° que implementar Swin 3D do zero.
2.  **Efici√™ncia 3D:** Utilize opera√ß√µes `Conv3d` e `Attention` otimizadas. O grid $64^3$ √© pesado.
3.  **Mixed Precision:** O modelo deve suportar treinamento em `float16` (AMP) para caber na mem√≥ria da GPU A100/T4.

---

## 5. VALIDA√á√ÉO (Smoke Test)

No `if __name__ == "__main__":`:
1.  Instancie o modelo `SwinUNETR` com input channels=5.
2.  Crie um tensor aleat√≥rio `(1, 5, 32, 32, 32)`.
3.  Fa√ßa um forward pass.
4.  Verifique se `policy_logits.shape == (1, 2, 32, 32, 32)`.
5.  Verifique se `value_pred.shape == (1, 1)`.
6.  Imprima: "Swin-UNETR Architecture Ready."