# ü§ñ MISS√ÉO: AGENTE 03 (NEURAL_VISION)

**Fun√ß√£o:** Arquiteto de Deep Learning (Vision Transformers).
**Paradigma:** Funcional Pr√°tico (Keras Functional API).
**Stack:** Python 3.10+, TensorFlow 2.x, NumPy.

---

## 1. CONTEXTO E OBJETIVO
Sua responsabilidade √© escrever o c√≥digo do m√≥dulo de Intelig√™ncia Artificial do **AlphaBuilder**. Este m√≥dulo ser√° importado e utilizado pelo motor de estrat√©gia (escrito por outro agente) para estimar a qualidade de designs estruturais.

**A Estrat√©gia de Unifica√ß√£o Volum√©trica:**
Voc√™ deve implementar uma arquitetura **3D Vision Transformer**.
*   O c√≥digo n√£o deve tratar problemas 2D e 3D de formas distintas.
*   O input para a rede neural ser√° sempre um **Volume Euclidiano** $(D, H, W, C)$.
*   Problemas 2D (como a viga do paper) s√£o tratados atrav√©s da **extrus√£o** da malha 2D ao longo do eixo Z (profundidade). A "espessura" da pe√ßa define quantas fatias de voxels ser√£o preenchidas no tensor de entrada.

---

## 2. ESTRUTURAS DE DADOS (INTERFACE)

Defina estas estruturas utilizando `dataclasses` imut√°veis. Elas servir√£o como contrato de dados para quem importar seu m√≥dulo.

```python
from dataclasses import dataclass
import tensorflow as tf
import numpy as np

# Constantes do Espa√ßo Can√¥nico de Entrada
# O modelo sempre espera este shape fixo.
MAX_DEPTH = 16   # Espessura m√°xima em voxels
MAX_HEIGHT = 64
MAX_WIDTH = 128
CHANNELS = 3     # (1: Material, 2: Suportes, 3: Cargas)

@dataclass(frozen=True)
class VolumetricInput:
    """
    Container imut√°vel para o tensor de entrada.
    Garante que o tensor esteja no formato (Batch, D, H, W, C).
    """
    tensor: tf.Tensor

@dataclass(frozen=True)
class TrainingBatch:
    """
    Par (Input, Target) para o loop de treinamento.
    """
    inputs: VolumetricInput
    targets: tf.Tensor  # Shape: (Batch, 1) -> Fitness Real
```

---

## 3. TAREFAS DE IMPLEMENTA√á√ÉO

Voc√™ deve produzir um arquivo (ou conjunto de arquivos) contendo as seguintes **Fun√ß√µes Puras** e **Construtores de Modelo**.

### 3.1. Pr√©-processamento: Extrus√£o e Tensoriza√ß√£o
Quem usar seu c√≥digo enviar√° matrizes NumPy 2D brutas e um inteiro de espessura. Voc√™ deve transformar isso no formato que a rede aceita.

*   **`prepare_volumetric_batch(grids_2d: list[np.ndarray], thicknesses: list[int]) -> VolumetricInput`**
    *   **Fun√ß√£o Pura.**
    *   **L√≥gica de Extrus√£o:** Para cada grid $G$ de dimens√£o $(H, W)$ e espessura $T$:
        1.  Crie um volume $V$ de zeros com shape $(MAX\_DEPTH, MAX\_HEIGHT, MAX\_WIDTH, 3)$.
        2.  Repita a grid $G$ nas primeiras $T$ fatias do eixo de profundidade ($z=0$ at√© $z=T-1$).
        3.  Fa√ßa o mesmo para os canais de Suporte e Carga (assumindo que permeiam a espessura).
    *   **Normaliza√ß√£o:** Garante `dtype=float32`.
    *   **Retorno:** Objeto `VolumetricInput` contendo o tensor em batch.

### 3.2. Arquitetura: 3D Vision Transformer
Implemente o construtor do modelo usando `tf.keras`.

*   **`build_3d_vit(patch_size: tuple[int, int, int] = (2, 8, 8)) -> tf.keras.Model`**
    *   **Entrada:** `(MAX_DEPTH, MAX_HEIGHT, MAX_WIDTH, 3)`.
    *   **Patching Volum√©trico:** Utilize `Conv3D` com stride igual ao tamanho do kernel para criar os embeddings lineares dos patches c√∫bicos.
    *   **Positional Embeddings:** Implemente uma camada customizada ou use `Embedding` somado, para que o modelo entenda coordenadas $(z, y, x)$. *Isso √© crucial para diferenciar uma camada superficial de uma interna.*
    *   **Transformer Block:** Implemente a sequ√™ncia padr√£o (Norm -> Attention -> Norm -> MLP). Use conex√µes residuais.
    *   **Head:** Global Average Pooling 3D seguido de MLP denso para regress√£o escalar (1 sa√≠da).

### 3.3. API de Treinamento e Infer√™ncia
Exponha fun√ß√µes que abstraiam a complexidade do TensorFlow.

*   **`train_step(model, batch: TrainingBatch, optimizer, loss_fn) -> dict`**
    *   Decore com `@tf.function`.
    *   Executa um passo de gradiente descendente.
    *   Retorna dicion√°rio de m√©tricas (Loss, MAE).

*   **`predict_fitness(model, grids: list[np.ndarray], thicknesses: list[int]) -> np.ndarray`**
    *   **Esta √© a fun√ß√£o que o c√≥digo do MCTS chamar√°.**
    *   Recebe dados brutos.
    *   Chama internamente `prepare_volumetric_batch`.
    *   Executa `model(input, training=False)`.
    *   Retorna array NumPy com os valores previstos.

---

## 4. REQUISITOS T√âCNICOS

1.  **Agnosticismo de Chamada:** Seu c√≥digo n√£o deve importar nada do m√≥dulo de F√≠sica ou do MCTS. Ele deve ser totalmente independente, dependendo apenas de NumPy e TensorFlow.
2.  **Tratamento de Padding:** O ViT deve ser robusto a voxels vazios. Como usamos *Zero Padding* para preencher o cubo at√© `MAX_DEPTH`, certifique-se de que o mecanismo de aten√ß√£o ou a normaliza√ß√£o n√£o sejam desestabilizados por muitos zeros. O uso de `LayerNormalization` geralmente resolve isso bem.
3.  **Persist√™ncia do Modelo:** Inclua fun√ß√µes simples `save_model(model, path)` e `load_model(path)` usando o formato `.keras` nativo.

---

## 5. VALIDA√á√ÉO (Smoke Test)

No final do seu script (bloco `if __name__ == "__main__":`), escreva um teste de integra√ß√£o interna:

1.  **Mock Data:** Crie uma lista com 2 matrizes aleat√≥rias $(64, 128)$. Defina espessuras `[1, 5]`.
2.  **Pipeline Check:** Chame `prepare_volumetric_batch` e verifique (`assert`) se o tensor resultante tem shape `(2, 16, 64, 128, 3)`.
3.  **Model Build:** Instancie o modelo com `build_3d_vit()`.
4.  **Forward Pass:** Passe o tensor pelo modelo e verifique se o output tem shape `(2, 1)`.
5.  **Output:** Imprima "Neural Module Ready. Input Shape: [...] Output: [...]".