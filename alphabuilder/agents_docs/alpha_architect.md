# ü§ñ MISS√ÉO: AGENTE 02 (ALPHA_ARCHITECT)

**Fun√ß√£o:** Motor de Busca (MCTS), L√≥gica de Jogo Bif√°sica e Gerenciamento de Estado.
**Paradigma:** Funcional Puro (Pure Functional Programming).
**Stack:** Python 3.10+, NumPy, SQLite, SciPy (Sparse Graph).

---

## 1. CONTEXTO E RESPONSABILIDADE
Voc√™ √© o kernel l√≥gico do **AlphaBuilder v1.1**.
Sua miss√£o √© orquestrar o epis√≥dio bif√°sico:
1.  **Fase 1 (Pathfinder):** Garantir conectividade entre Cargas e Suportes (Search for Function).
2.  **Fase 2 (Sculptor):** Otimizar a forma para reduzir volume mantendo a rigidez (Search for Form).

---

## 2. TIPAGEM E ESTRUTURAS DE DADOS

```python
from typing import NamedTuple, Tuple, FrozenSet, Literal, Optional
import numpy as np

# Tipos Primitivos
Coord = Tuple[int, int, int] # (z, y, x) - Agora 3D nativo
ActionType = Literal['ADD', 'REMOVE']
PhaseType = Literal['PATHFINDING', 'REFINEMENT']

class GameAction(NamedTuple):
    """A√ß√£o at√¥mica do jogo."""
    type: ActionType
    coord: Coord
    prob_score: float # Score vindo da Policy Network (Swin-UNETR)

class DesignState(NamedTuple):
    """
    Estado completo e imut√°vel do sistema (Tensor 5D Abstrato).
    """
    grid: np.ndarray              # 3D Array (D, H, W) - Canal de Densidade
    supports: Tuple[Coord, ...]   # Coordenadas fixas
    loads: Tuple[Coord, ...]      # Coordenadas de carga + Vetores For√ßa
    phase: PhaseType              # Fase atual
    
    # Metadados de Grafo (Cache)
    is_connected: bool            
    volume: int                   
    
    def __hash__(self):
        return hash(self.grid.tobytes())

class SimulationRecord(NamedTuple):
    """DTO para persist√™ncia no DB."""
    episode_id: str
    step: int
    phase: str
    state_bytes: bytes # Compress√£o do grid
    action_taken: str
    reward: float
    is_valid: bool
```

---

## 3. IMPLEMENTA√á√ÉO FUNCIONAL (CORE)

### 3.1. M√°quina de Estados (Game Loop)

*   **`get_legal_actions(state: DesignState, policy_mask: np.ndarray) -> Tuple[GameAction, ...]`**
    *   **Fase 1 (PATHFINDING):**
        *   Objetivo: Conectar Sementes (Suportes) √†s Metas (Cargas).
        *   A√ß√µes: Predominantemente `ADD` em vizinhos de voxels existentes.
        *   Restri√ß√£o: N√£o permitir `REMOVE` que quebre caminhos existentes.
    *   **Fase 2 (REFINEMENT):**
        *   Objetivo: Remover massa ineficiente.
        *   A√ß√µes: `REMOVE` em bordas (eros√£o) e `ADD` em √°reas de alta tens√£o (refor√ßo).
        *   **Pruning Neural:** Utilize a `policy_mask` (output da Swin-UNETR) para filtrar a√ß√µes. Retorne apenas as Top-K a√ß√µes mais prov√°veis sugeridas pela rede. Isso reduz o espa√ßo de busca de $64^3$ para ~50 a√ß√µes vi√°veis.

*   **`transition(state: DesignState, action: GameAction) -> DesignState`**
    *   Aplica a a√ß√£o.
    *   Verifica conectividade (Union-Find ou BFS).
    *   **Trigger de Fase:** Se `state.phase == PATHFINDING` E `check_full_connectivity(new_grid)` for True $\to$ Muda para `REFINEMENT`.

### 3.2. MCTS Guiado por Rede (Neural MCTS)

*   **`select_action_mcts(root: Node, network_fn: Callable) -> GameAction`**
    *   Implemente um MCTS modificado.
    *   **Expans√£o:** Use a Policy Head da rede para priorizar quais n√≥s filhos criar.
    *   **Simula√ß√£o (Rollout):** Em vez de rollout aleat√≥rio, use a Value Head da rede para estimar o retorno futuro do estado folha.
    *   **Backprop:** Atualize os valores $Q(s, a)$ na √°rvore.

---

## 4. LOOP DE EXECU√á√ÉO

```python
def run_episode(episode_id: str, config: dict, agent_net, physics_oracle):
    state = init_state(config)
    
    while not is_terminal(state):
        # 1. Infer√™ncia Neural
        # O agente "olha" para o tabuleiro e sugere a√ß√µes (Policy) e avalia a situa√ß√£o (Value)
        policy_logits, value_est = agent_net.predict(state.grid)
        
        # 2. Busca (MCTS)
        # O agente "pensa" simulando futuros poss√≠veis, guiado pela intui√ß√£o da rede
        best_action = run_mcts(state, policy_logits)
        
        # 3. A√ß√£o Real
        next_state = transition(state, best_action)
        
        # 4. Feedback F√≠sico (Apenas Fase 2)
        reward = 0.0
        if next_state.phase == 'REFINEMENT':
            # O Solver FEM √© o "Ground Truth" que treina a rede
            fem_result = physics_oracle.solve(next_state.grid)
            reward = calculate_reward(fem_result)
            
        # 5. Persist√™ncia (Experience Replay)
        save_step(episode_id, state, best_action, reward)
        
        state = next_state
```

---

## 5. REQUISITOS DE VALIDA√á√ÉO

1.  **Teste de Transi√ß√£o de Fase:** Crie um cen√°rio onde falta apenas 1 voxel para conectar. Force a a√ß√£o `ADD` nesse voxel. Verifique se o estado resultante tem `phase='REFINEMENT'`.
2.  **Teste de Conectividade R√°pida:** O algoritmo de verifica√ß√£o de grafo deve rodar em < 10ms para grids $32^3$.
3.  **Teste de Pruning:** Verifique se `get_legal_actions` ignora voxels com probabilidade zero na m√°scara neural.
