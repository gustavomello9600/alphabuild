"""
AlphaBuilder v3.1 - Colab/Kaggle Entrypoint

Script para configuraÃ§Ã£o e validaÃ§Ã£o do ambiente em notebooks.
Instala dependÃªncias, verifica GPU e roda smoke tests.

Uso no Colab/Kaggle:
    !git clone https://github.com/user/alphabuild.git
    %cd alphabuild
    !python -m alphabuilder.src.neural.colab_entrypoint
"""
import os
import subprocess
import sys
from pathlib import Path

# Add project root to path
# File: .../alphabuilder/src/neural/colab_entrypoint.py
# Project root: 4 levels up
project_root = Path(__file__).resolve().parent.parent.parent.parent
sys.path.insert(0, str(project_root))


def install_dependencies():
    """Instala dependÃªncias necessÃ¡rias para treino."""
    print("=" * 60)
    print("ğŸ“¦ Instalando dependÃªncias para AlphaBuilder v3.1...")
    print("=" * 60)
    
    # DependÃªncias Python bÃ¡sicas
    packages = [
        "torch",
        "monai>=1.0.0",
        "einops",
        "numpy",
        "scipy",
        "tqdm",
    ]
    
    subprocess.check_call(
        [sys.executable, "-m", "pip", "install", "-q"] + packages
    )
    print("âœ“ DependÃªncias Python instaladas")
    
    # InstalaÃ§Ã£o do FEniCSx
    print("\nğŸ“¦ Verificando FEniCSx...")
    try:
        import dolfinx
        print(f"âœ“ FEniCSx jÃ¡ instalado: {dolfinx.__version__}")
    except ImportError:
        print("âš ï¸  FEniCSx nÃ£o encontrado. Tentando instalar...")
        
        # Detecta se estÃ¡ no Colab
        try:
            import google.colab
            is_colab = True
        except ImportError:
            is_colab = False
        
        if is_colab:
            print("   Detectado: Google Colab")
            print("   Instalando via fem-on-colab (pode levar alguns minutos)...")
            try:
                # URL correto do fem-on-colab
                install_cmd = (
                    'wget -q "https://fem-on-colab.github.io/releases/fenicsx-install-release-real.sh" '
                    '-O "/tmp/fenicsx-install.sh" && bash "/tmp/fenicsx-install.sh"'
                )
                result = subprocess.run(install_cmd, shell=True, capture_output=True, text=True)
                
                if result.returncode == 0:
                    # Recarrega mÃ³dulos
                    import importlib
        import dolfinx
                    print(f"âœ“ FEniCSx instalado: {dolfinx.__version__}")
                else:
                    print(f"âœ— Falha na instalaÃ§Ã£o: {result.stderr[:200]}")
                    print("   Tente reiniciar o runtime do Colab e executar novamente.")
            except Exception as e:
                print(f"âœ— Erro: {e}")
        else:
            print("   NÃ£o estÃ¡ no Google Colab.")
            print("\n   Para instalar FEniCSx:")
            print("   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
            print("   ğŸ“Œ Kaggle: NÃ£o suportado (use dados prÃ©-gerados)")
            print("   ğŸ“Œ Local:  conda install -c conda-forge fenics-dolfinx mpich mpi4py")
            print("   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
            print("\n   â„¹ï¸  FEniCSx Ã© necessÃ¡rio APENAS para geraÃ§Ã£o de dados.")
            print("      O treino da rede neural funciona sem ele.")


def check_gpu():
    """Verifica disponibilidade de GPU."""
    import torch
    
    print("\n" + "=" * 60)
    print("ğŸ–¥ï¸  Verificando Hardware...")
    print("=" * 60)
    
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9
        print(f"âœ“ GPU Detectada: {gpu_name}")
        print(f"  MemÃ³ria: {gpu_mem:.1f} GB")
        return True
    else:
        print("âš ï¸  WARNING: Nenhuma GPU detectada!")
        print("  O treino serÃ¡ MUITO lento em CPU.")
        return False


def run_smoke_tests():
    """Executa testes de validaÃ§Ã£o da arquitetura."""
    import torch
    
    print("\n" + "=" * 60)
    print("ğŸ§ª Executando Smoke Tests...")
    print("=" * 60)
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # Test 1: Model instantiation
    print("\n[1/4] Instanciando modelo v3.1...")
    try:
        from alphabuilder.src.neural.model import AlphaBuilderV31
        
        model = AlphaBuilderV31(
            in_channels=7,
            out_channels=2,
            feature_size=24,
            use_swin=True  # Tenta usar SwinUNETR
        ).to(device)
        print("âœ“ Modelo instanciado com sucesso")
        
        # Parameter count
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        print(f"  ParÃ¢metros totais: {total_params:,}")
        print(f"  ParÃ¢metros treinÃ¡veis: {trainable_params:,}")
        
    except Exception as e:
        print(f"âœ— Falha na instanciaÃ§Ã£o: {e}")
        return False
    
    # Test 2: Forward pass (standard resolution)
    print("\n[2/4] Forward pass (64x32x8)...")
    try:
        x = torch.randn(1, 7, 64, 32, 8).to(device)
        with torch.no_grad():
            policy, value = model(x)
        
        assert policy.shape == (1, 2, 64, 32, 8), f"Policy shape errado: {policy.shape}"
        assert value.shape == (1, 1), f"Value shape errado: {value.shape}"
        print(f"âœ“ Policy shape: {policy.shape}")
        print(f"âœ“ Value shape: {value.shape}, valor: {value.item():.4f}")
        
    except Exception as e:
        print(f"âœ— Falha no forward pass: {e}")
        return False
    
    # Test 3: Dynamic resolution (non-standard but valid for Swin)
    print("\n[3/4] Dynamic padding (48x24x16)...")
    try:
        # Swin requires reasonable spatial dimensions (bottleneck must be > 1x1x1)
        x_small = torch.randn(1, 7, 48, 24, 16).to(device)
        with torch.no_grad():
            policy_s, value_s = model(x_small)
        
        assert policy_s.shape == (1, 2, 48, 24, 16), f"Policy shape errado: {policy_s.shape}"
        print(f"âœ“ Dynamic resolution OK: {policy_s.shape}")
        
    except Exception as e:
        print(f"âœ— Falha no dynamic padding: {e}")
        return False
    
    # Test 4: Backward pass (gradient check)
    print("\n[4/4] Backward pass (gradient flow)...")
    try:
        model.train()
        x_grad = torch.randn(1, 7, 64, 32, 8, requires_grad=True).to(device)
        policy_g, value_g = model(x_grad)
        
        loss = policy_g.sum() + value_g.sum()
        loss.backward()
        
        # Check gradients exist
        has_grad = any(
            p.grad is not None and p.grad.abs().sum() > 0 
            for p in model.parameters()
        )
        assert has_grad, "Nenhum gradiente encontrado!"
        print("âœ“ Gradientes fluindo corretamente")
        
    except Exception as e:
        print(f"âœ— Falha no backward pass: {e}")
        return False
    
    return True


def run_data_augmentation_tests():
    """Testa funÃ§Ãµes de data augmentation."""
    import numpy as np
    
    print("\n" + "=" * 60)
    print("ğŸ”„ Testando Data Augmentation...")
    print("=" * 60)
    
    try:
        from alphabuilder.src.neural.augmentation import (
            rotate_90_z, flip_y, erosion_attack, load_multiplier, sabotage, saboteur
        )
        
        # Create sample data
        state = np.random.rand(7, 32, 16, 4).astype(np.float32)
        state[0] = (state[0] > 0.5).astype(np.float32)  # Binary density
        policy = np.zeros((2, 32, 16, 4), dtype=np.float32)
        
        # Test each augmentation
        augmentations = [
            ("rotate_90_z", lambda: rotate_90_z(state, policy)),
            ("flip_y", lambda: flip_y(state, policy)),
            ("erosion_attack", lambda: erosion_attack(state, policy, 0.5)),
            ("load_multiplier", lambda: load_multiplier(state, policy, 0.5)),
            ("sabotage", lambda: sabotage(state, policy, 0.5)),
            ("saboteur", lambda: saboteur(state, policy, 0.5)),
        ]
        
        for name, func in augmentations:
            try:
                result = func()
                print(f"âœ“ {name}")
            except Exception as e:
                print(f"âœ— {name}: {e}")
                return False
        
        return True
        
    except Exception as e:
        print(f"âœ— Falha ao importar augmentations: {e}")
        return False


def main():
    """Entrypoint principal."""
    print("\n" + "=" * 60)
    print("ğŸ—ï¸  AlphaBuilder v3.1 - Setup Colab/Kaggle")
    print("=" * 60)
    
    # 1. Install dependencies
    install_dependencies()
    
    # 2. Check GPU
    has_gpu = check_gpu()
    
    # 3. Run smoke tests
    model_ok = run_smoke_tests()
    
    # 4. Test augmentations
    aug_ok = run_data_augmentation_tests()
    
    # Summary
    print("\n" + "=" * 60)
    print("ğŸ“Š Resumo")
    print("=" * 60)
    
    print(f"  GPU disponÃ­vel: {'âœ“ Sim' if has_gpu else 'âœ— NÃ£o'}")
    print(f"  Modelo v3.1:    {'âœ“ OK' if model_ok else 'âœ— Falhou'}")
    print(f"  Augmentation:   {'âœ“ OK' if aug_ok else 'âœ— Falhou'}")
    
    if model_ok and aug_ok:
        print("\nğŸ‰ Ambiente pronto para treino!")
        print("\nPrÃ³ximos passos:")
        print("  1. Monte o Google Drive: drive.mount('/content/drive')")
        print("  2. Copie os dados: cp /content/drive/MyDrive/data/*.db ./data/")
        print("  3. Inicie o treino:")
        print("     from alphabuilder.src.neural.trainer import train_one_epoch")
        print("     from alphabuilder.src.neural.model import AlphaBuilderV31")
        print("     from alphabuilder.src.neural.dataset import TopologyDatasetV31")
    else:
        print("\nâš ï¸  Alguns testes falharam. Verifique os erros acima.")
        return 1
    
    return 0


if __name__ == "__main__":
    sys.exit(main())

