"""
Gerador de Relat√≥rio de Qualidade de Dados de Treino.

Gera um relat√≥rio .md completo com an√°lise dos dados gerados
durante o teste de integra√ß√£o.
"""
import sqlite3
import json
import numpy as np
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List, Tuple

from alphabuilder.src.logic.storage import deserialize_state, sparse_decode
from alphabuilder.src.neural.dataset import deserialize_sparse, deserialize_array


def generate_quality_report(db_path: Path, output_path: Path) -> str:
    """
    Gera um relat√≥rio completo de qualidade dos dados de treino.
    
    Args:
        db_path: Caminho para o banco de dados SQLite.
        output_path: Caminho para salvar o relat√≥rio .md.
        
    Returns:
        Caminho do relat√≥rio gerado.
    """
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    report_lines = []
    
    # ==================== HEADER ====================
    report_lines.append("# üìä Relat√≥rio de Qualidade de Dados de Treino")
    report_lines.append("")
    report_lines.append(f"**Gerado em:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report_lines.append(f"**Banco de Dados:** `{db_path.name}`")
    report_lines.append("")
    report_lines.append("---")
    report_lines.append("")
    
    # ==================== RESUMO GERAL ====================
    report_lines.append("## 1. Resumo Geral")
    report_lines.append("")
    
    # Total de registros
    cursor.execute("SELECT COUNT(*) FROM training_data")
    total_records = cursor.fetchone()[0]
    
    # Epis√≥dios √∫nicos
    cursor.execute("SELECT COUNT(DISTINCT episode_id) FROM training_data")
    total_episodes = cursor.fetchone()[0]
    
    # Por fase
    cursor.execute("SELECT phase, COUNT(*) FROM training_data GROUP BY phase")
    phase_counts = dict(cursor.fetchall())
    
    report_lines.append(f"| M√©trica | Valor |")
    report_lines.append(f"|---------|-------|")
    report_lines.append(f"| Total de Registros | **{total_records}** |")
    report_lines.append(f"| Epis√≥dios √önicos | **{total_episodes}** |")
    report_lines.append(f"| Registros GROWTH (Fase 1) | {phase_counts.get('GROWTH', 0)} |")
    report_lines.append(f"| Registros REFINEMENT (Fase 2) | {phase_counts.get('REFINEMENT', 0)} |")
    report_lines.append("")
    
    # ==================== AN√ÅLISE POR EPIS√ìDIO ====================
    report_lines.append("## 2. An√°lise por Epis√≥dio")
    report_lines.append("")
    
    cursor.execute("""
        SELECT episode_id, 
               COUNT(*) as records,
               SUM(CASE WHEN phase = 'GROWTH' THEN 1 ELSE 0 END) as growth,
               SUM(CASE WHEN phase = 'REFINEMENT' THEN 1 ELSE 0 END) as refinement,
               AVG(fitness_score) as avg_fitness,
               MIN(fitness_score) as min_fitness,
               MAX(fitness_score) as max_fitness
        FROM training_data
        GROUP BY episode_id
    """)
    episodes = cursor.fetchall()
    
    report_lines.append("| Episode ID | Records | GROWTH | REFINEMENT | Avg Fitness | Min | Max |")
    report_lines.append("|------------|---------|--------|------------|-------------|-----|-----|")
    
    for ep in episodes:
        ep_id_short = ep[0][:8] + "..." if len(ep[0]) > 8 else ep[0]
        report_lines.append(
            f"| `{ep_id_short}` | {ep[1]} | {ep[2]} | {ep[3]} | "
            f"{ep[4]:.4f} | {ep[5]:.4f} | {ep[6]:.4f} |"
        )
    report_lines.append("")
    
    # ==================== AN√ÅLISE DE TENSORES ====================
    report_lines.append("## 3. An√°lise de Tensores")
    report_lines.append("")
    
    # Amostra alguns tensores para an√°lise
    cursor.execute("SELECT state_blob, policy_blob, phase FROM training_data LIMIT 10")
    samples = cursor.fetchall()
    
    if samples:
        state_sample = deserialize_state(samples[0][0])
        policy_sample = deserialize_state(samples[0][1])
        
        report_lines.append(f"### 3.1 Dimens√µes dos Tensores")
        report_lines.append("")
        report_lines.append(f"| Tensor | Shape | Dtype |")
        report_lines.append(f"|--------|-------|-------|")
        report_lines.append(f"| State | `{state_sample.shape}` | `{state_sample.dtype}` |")
        report_lines.append(f"| Policy | `{policy_sample.shape}` | `{policy_sample.dtype}` |")
        report_lines.append("")
        
        # An√°lise dos canais do state
        report_lines.append(f"### 3.2 An√°lise dos Canais do State (7 canais v3.1)")
        report_lines.append("")
        channel_names = [
            "Density (œÅ)", "Mask X (ux)", "Mask Y (uy)", "Mask Z (uz)",
            "Force X (Fx)", "Force Y (Fy)", "Force Z (Fz)"
        ]
        
        report_lines.append(f"| Canal | Nome | Min | Max | Mean | Non-zero % |")
        report_lines.append(f"|-------|------|-----|-----|------|------------|")
        
        for i, name in enumerate(channel_names):
            ch = state_sample[i]
            nonzero_pct = (ch != 0).sum() / ch.size * 100
            report_lines.append(
                f"| {i} | {name} | {ch.min():.4f} | {ch.max():.4f} | "
                f"{ch.mean():.4f} | {nonzero_pct:.2f}% |"
            )
        report_lines.append("")
        
        # An√°lise dos canais da policy
        report_lines.append(f"### 3.3 An√°lise dos Canais da Policy (2 canais)")
        report_lines.append("")
        policy_names = ["Add (Adi√ß√£o)", "Remove (Remo√ß√£o)"]
        
        report_lines.append(f"| Canal | Nome | Min | Max | Mean | Non-zero % |")
        report_lines.append(f"|-------|------|-----|-----|------|------------|")
        
        for i, name in enumerate(policy_names):
            ch = policy_sample[i]
            nonzero_pct = (ch != 0).sum() / ch.size * 100
            report_lines.append(
                f"| {i} | {name} | {ch.min():.4f} | {ch.max():.4f} | "
                f"{ch.mean():.4f} | {nonzero_pct:.2f}% |"
            )
        report_lines.append("")
    
    # ==================== AN√ÅLISE DE FITNESS SCORE (VALUE TARGET) ====================
    report_lines.append("## 4. An√°lise de Fitness Score (Value Target)")
    report_lines.append("")
    
    # Detecta schema e busca scores
    from alphabuilder.src.logic.storage import has_new_schema
    is_v2 = has_new_schema(db_path)
    
    if is_v2:
        cursor.execute("SELECT fitness_score FROM records")
    else:
        cursor.execute("SELECT fitness_score FROM training_data")
    
    all_scores = [row[0] for row in cursor.fetchall()]
    scores_array = np.array(all_scores) if all_scores else np.array([])
    
    if len(scores_array) == 0:
        report_lines.append("‚ö†Ô∏è Nenhum score encontrado no banco de dados.")
        report_lines.append("")
        # Salva e retorna
        report_content = "\n".join(report_lines)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        output_path.write_text(report_content, encoding='utf-8')
        return str(output_path)
    
    report_lines.append(f"### 4.1 Estat√≠sticas Gerais")
    report_lines.append("")
    report_lines.append(f"| Estat√≠stica | Valor |")
    report_lines.append(f"|-------------|-------|")
    report_lines.append(f"| M√≠nimo | {scores_array.min():.6f} |")
    report_lines.append(f"| M√°ximo | {scores_array.max():.6f} |")
    report_lines.append(f"| M√©dia | {scores_array.mean():.6f} |")
    report_lines.append(f"| Mediana | {np.median(scores_array):.6f} |")
    report_lines.append(f"| Desvio Padr√£o | {scores_array.std():.6f} |")
    report_lines.append(f"| Percentil 25 | {np.percentile(scores_array, 25):.6f} |")
    report_lines.append(f"| Percentil 75 | {np.percentile(scores_array, 75):.6f} |")
    report_lines.append("")
    
    # Distribui√ß√£o por faixa
    report_lines.append(f"### 4.2 Distribui√ß√£o por Faixa")
    report_lines.append("")
    bins = [(-1.1, -0.5), (-0.5, 0.0), (0.0, 0.5), (0.5, 1.1)]
    
    report_lines.append(f"| Faixa | Contagem | Percentual |")
    report_lines.append(f"|-------|----------|------------|")
    
    for low, high in bins:
        count = ((scores_array >= low) & (scores_array < high)).sum()
        pct = count / len(scores_array) * 100
        report_lines.append(f"| [{low:.1f}, {high:.1f}) | {count} | {pct:.1f}% |")
    report_lines.append("")
    
    # Por fase
    report_lines.append(f"### 4.3 Fitness por Fase")
    report_lines.append("")
    
    cursor.execute("""
        SELECT phase, 
               AVG(fitness_score), 
               MIN(fitness_score), 
               MAX(fitness_score),
               COUNT(*)
        FROM training_data 
        GROUP BY phase
    """)
    phase_stats = cursor.fetchall()
    
    report_lines.append(f"| Fase | Count | Avg | Min | Max |")
    report_lines.append(f"|------|-------|-----|-----|-----|")
    
    for ps in phase_stats:
        report_lines.append(f"| {ps[0]} | {ps[4]} | {ps[1]:.4f} | {ps[2]:.4f} | {ps[3]:.4f} |")
    report_lines.append("")
    
    # ==================== AN√ÅLISE DE POLICY TARGETS ====================
    report_lines.append("## 5. An√°lise de Policy Targets")
    report_lines.append("")
    
    # Estat√≠sticas de balanceamento de classes
    report_lines.append(f"### 5.1 Balanceamento de Classes")
    report_lines.append("")
    
    # Amostra mais registros (suporta schema v1 e v2)
    from alphabuilder.src.logic.storage import has_new_schema, sparse_decode, deserialize_array
    is_v2 = has_new_schema(db_path)
    
    if is_v2:
        cursor.execute("""
            SELECT r.policy_add_blob, r.policy_remove_blob, r.phase, e.resolution
            FROM records r
            JOIN episodes e ON r.episode_id = e.episode_id
            LIMIT 1000
        """)
        policy_samples = cursor.fetchall()
        
        add_ratios = []
        rem_ratios = []
        growth_add_ratios = []
        refinement_add_ratios = []
        
        for policy_add_blob, policy_remove_blob, phase, resolution_json in policy_samples:
            if policy_add_blob and policy_remove_blob:
                # Schema v2: policy est√° em formato esparso
                resolution = tuple(json.loads(resolution_json))
                
                # Deserializa esparso
                add_idx, add_val = deserialize_sparse(policy_add_blob)
                rem_idx, rem_val = deserialize_sparse(policy_remove_blob)
                
                add_ch = sparse_decode(add_idx, add_val, resolution)
                rem_ch = sparse_decode(rem_idx, rem_val, resolution)
                
                add_ratio = (add_ch > 0.5).sum() / add_ch.size
                rem_ratio = (rem_ch > 0.5).sum() / rem_ch.size
                
                add_ratios.append(add_ratio)
                rem_ratios.append(rem_ratio)
                
                if phase == 'GROWTH':
                    growth_add_ratios.append(add_ratio)
                else:
                    refinement_add_ratios.append(add_ratio)
    else:
        cursor.execute("SELECT policy_blob, phase FROM training_data LIMIT 1000")
        policy_samples = cursor.fetchall()
        
        add_ratios = []
        rem_ratios = []
        growth_add_ratios = []
        refinement_add_ratios = []
        
        for policy_blob, phase in policy_samples:
            policy = deserialize_state(policy_blob)
            add_ch = policy[0]
            rem_ch = policy[1]
            
            add_ratio = (add_ch > 0.5).sum() / add_ch.size
            rem_ratio = (rem_ch > 0.5).sum() / rem_ch.size
            
            add_ratios.append(add_ratio)
            rem_ratios.append(rem_ratio)
            
            if phase == 'GROWTH':
                growth_add_ratios.append(add_ratio)
            else:
                refinement_add_ratios.append(add_ratio)
    
    add_ratios = np.array(add_ratios) if add_ratios else np.array([])
    rem_ratios = np.array(rem_ratios) if rem_ratios else np.array([])
    
    if len(add_ratios) == 0:
        report_lines.append("‚ö†Ô∏è Nenhuma policy encontrada no banco de dados.")
        report_lines.append("")
        # Salva e retorna
        report_content = "\n".join(report_lines)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        output_path.write_text(report_content, encoding='utf-8')
        return str(output_path)
    
    report_lines.append(f"| M√©trica | Canal ADD | Canal REMOVE |")
    report_lines.append(f"|---------|-----------|--------------|")
    report_lines.append(f"| M√©dia % Positivos | {add_ratios.mean()*100:.2f}% | {rem_ratios.mean()*100:.2f}% |")
    report_lines.append(f"| Mediana % Positivos | {np.median(add_ratios)*100:.2f}% | {np.median(rem_ratios)*100:.2f}% |")
    report_lines.append(f"| Max % Positivos | {add_ratios.max()*100:.2f}% | {rem_ratios.max()*100:.2f}% |")
    report_lines.append("")
    
    # Recomenda√ß√£o de pos_weight
    avg_add = add_ratios.mean()
    avg_rem = rem_ratios.mean()
    
    if avg_add > 0:
        recommended_add_weight = min(15, max(1, (1 - avg_add) / avg_add))
    else:
        recommended_add_weight = 10
        
    if avg_rem > 0:
        recommended_rem_weight = min(15, max(1, (1 - avg_rem) / avg_rem))
    else:
        recommended_rem_weight = 5
    
    report_lines.append(f"### 5.2 Recomenda√ß√£o de pos_weight (BCEWithLogitsLoss)")
    report_lines.append("")
    report_lines.append(f"| Canal | pos_weight Recomendado |")
    report_lines.append(f"|-------|------------------------|")
    report_lines.append(f"| ADD | **{recommended_add_weight:.1f}** |")
    report_lines.append(f"| REMOVE | **{recommended_rem_weight:.1f}** |")
    report_lines.append("")
    
    # Por fase
    report_lines.append(f"### 5.3 Balanceamento por Fase")
    report_lines.append("")
    
    if growth_add_ratios:
        growth_add = np.array(growth_add_ratios)
        report_lines.append(f"**GROWTH (Fase 1):** ADD m√©dio = {growth_add.mean()*100:.2f}%")
    
    if refinement_add_ratios:
        ref_add = np.array(refinement_add_ratios)
        report_lines.append(f"**REFINEMENT (Fase 2):** ADD m√©dio = {ref_add.mean()*100:.2f}%")
    report_lines.append("")
    
    # ==================== AN√ÅLISE DE METADADOS ====================
    report_lines.append("## 6. An√°lise de Metadados")
    report_lines.append("")
    
    # BC Types
    cursor.execute("SELECT metadata FROM training_data WHERE metadata IS NOT NULL")
    metadata_rows = cursor.fetchall()
    
    bc_types = {}
    strategies = {}
    
    for row in metadata_rows:
        try:
            meta = json.loads(row[0])
            bc = meta.get('bc_type', 'unknown')
            bc_types[bc] = bc_types.get(bc, 0) + 1
            
            strategy = meta.get('strategy', 'unknown')
            strategies[strategy] = strategies.get(strategy, 0) + 1
        except:
            pass
    
    report_lines.append(f"### 6.1 Boundary Conditions (BC Types)")
    report_lines.append("")
    report_lines.append(f"| BC Type | Contagem | Percentual |")
    report_lines.append(f"|---------|----------|------------|")
    
    for bc, count in bc_types.items():
        pct = count / total_records * 100
        report_lines.append(f"| {bc} | {count} | {pct:.1f}% |")
    report_lines.append("")
    
    report_lines.append(f"### 6.2 Estrat√©gias de Gera√ß√£o")
    report_lines.append("")
    report_lines.append(f"| Estrat√©gia | Contagem | Percentual |")
    report_lines.append(f"|------------|----------|------------|")
    
    for strat, count in strategies.items():
        pct = count / total_records * 100
        report_lines.append(f"| {strat} | {count} | {pct:.1f}% |")
    report_lines.append("")
    
    # ==================== AMOSTRAS ALEAT√ìRIAS ====================
    report_lines.append("## 7. Amostras Aleat√≥rias")
    report_lines.append("")
    
    cursor.execute("""
        SELECT episode_id, step, phase, fitness_score, metadata 
        FROM training_data 
        ORDER BY RANDOM() 
        LIMIT 10
    """)
    random_samples = cursor.fetchall()
    
    report_lines.append(f"| # | Episode | Step | Phase | Fitness | BC Type |")
    report_lines.append(f"|---|---------|------|-------|---------|---------|")
    
    for i, sample in enumerate(random_samples, 1):
        ep_short = sample[0][:8] + "..."
        try:
            meta = json.loads(sample[4]) if sample[4] else {}
            bc = meta.get('bc_type', 'N/A')
        except:
            bc = 'N/A'
        
        report_lines.append(
            f"| {i} | `{ep_short}` | {sample[1]} | {sample[2]} | "
            f"{sample[3]:.4f} | {bc} |"
        )
    report_lines.append("")
    
    # ==================== VALIDA√á√ÉO v3.1 ====================
    report_lines.append("## 8. Valida√ß√£o de Conformidade v3.1")
    report_lines.append("")
    
    checks = []
    
    # Check 1: 7 canais
    if samples:
        state = deserialize_state(samples[0][0])
        checks.append(("State tem 7 canais", state.shape[0] == 7))
    
    # Check 2: Policy tem 2 canais
    if samples:
        policy = deserialize_state(samples[0][1])
        checks.append(("Policy tem 2 canais", policy.shape[0] == 2))
    
    # Check 3: Ambas as fases presentes
    checks.append(("Fase GROWTH presente", phase_counts.get('GROWTH', 0) > 0))
    checks.append(("Fase REFINEMENT presente", phase_counts.get('REFINEMENT', 0) > 0))
    
    # Check 4: Fitness score em [-1, 1]
    checks.append(("Fitness score em [-1, 1]", scores_array.min() >= -1 and scores_array.max() <= 1))
    
    # Check 5: Metadados com bc_type
    checks.append(("Metadados bc_type presentes", len(bc_types) > 0))
    
    # Check 6: dtype float32 para policy
    if samples:
        policy = deserialize_state(samples[0][1])
        checks.append(("Policy dtype √© float32", policy.dtype == np.float32))
    
    report_lines.append(f"| Check | Status |")
    report_lines.append(f"|-------|--------|")
    
    all_passed = True
    for check_name, passed in checks:
        status = "‚úÖ PASS" if passed else "‚ùå FAIL"
        if not passed:
            all_passed = False
        report_lines.append(f"| {check_name} | {status} |")
    
    report_lines.append("")
    
    if all_passed:
        report_lines.append("### ‚úÖ Todos os checks de conformidade v3.1 passaram!")
    else:
        report_lines.append("### ‚ö†Ô∏è Alguns checks falharam. Verificar implementa√ß√£o.")
    report_lines.append("")
    
    # ==================== FOOTER ====================
    report_lines.append("---")
    report_lines.append("")
    report_lines.append("*Relat√≥rio gerado automaticamente pelo teste de integra√ß√£o AlphaBuilder v3.1*")
    
    conn.close()
    
    # Salva o relat√≥rio
    report_content = "\n".join(report_lines)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text(report_content, encoding='utf-8')
    
    return str(output_path)

